---
title: "Overview"
---
Here we provide you with a comprehensive guide for all things Cerebras. You’ll find detailed information on our core concepts, workflows, features, and the Cerebras PyTorch API. Explore the Cerebras Model Zoo with its pre-configured Large Language Models (LLM), Computer Vision (CV) models, and multimodal support for models like LLaVA, or bring your own PyTorch ML model and dataset.

The [Cerebras Wafer-Scale Cluster](./concepts/cerebras-wafer-scale-cluster.mdx) is meticulously engineered to enable the training of neural networks with remarkably efficient linear scaling across millions of cores, all without the complexities of traditional distributed computing. This portal includes set-up guides for establishing a Cerebras virtual environment and using the Cerebras Model Zoo. You’ll also find step-by-step tutorials and how-to guides covering every aspect in detail.

## Resources

*   Explore the [Cerebras Model Zoo](https://github.com/Cerebras/modelzoo) for a collection of [pre-built models](../model-zoo/model-zoo-overview.mdx).

*   Dive into [pre-training](Quickstart-for-pretrain.html) and [fine-tuning](Quickstart-for-fine-tune.html) a model using our QuickStart guides.

*   Use the [Cerebras PyTorch API](../api/cerebras_pytorch/index.html#cstorch-api-index) to integrate Cerebras technology with PyTorch for optimized performance and seamless model training.

*   Read through our [Core workflows](../Model-zoo/core_workflows/index.html) to learn about data preprocessing, evaluations, and training on Cerebras systems.

*   View our release version 1.6.1 documentation [here](https://docs.cerebras.net/en/latest/original/index.html).
